# Multi-node-training on slurm with PyTorch

### run command in cluster
```
num_batches=1000 sbatch -D . -p <partition> train.slurm -v
```
